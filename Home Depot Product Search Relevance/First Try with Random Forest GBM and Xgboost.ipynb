{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ngram\n",
    "from nlp_utils import stopwords, english_stemmer, stem_tokens, getTFV\n",
    "import cPickle\n",
    "import config\n",
    "\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import decomposition, pipeline, metrics, grid_search\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from nltk.stem.porter import *\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "from utility import correct_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('input/train.csv', encoding='ISO-8859-1')\n",
    "df_test = pd.read_csv('input/test.csv', encoding='ISO-8859-1')\n",
    "df_pro_desc = pd.read_csv('input/product_descriptions.csv')\n",
    "df_attr = pd.read_csv('input/attributes.csv')\n",
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\n",
    "\n",
    "num_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def str_stem(s):\n",
    "    if isinstance(s, str):\n",
    "        s = correct_string(s)\n",
    "        s = \" \".join([stemmer.stem(re.sub('[^A-Za-z0-9-./]', ' ', word))\n",
    "                      for word in s.split(\" \")])\n",
    "        s = s.lower()\n",
    "        return s\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_common_word(str1, str2):\n",
    "    str1, str2 = str1.lower(), str2.lower()\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt\n",
    "\n",
    "def str_whole_word(str1, str2, i_):\n",
    "    str1, str2 = str1.lower().strip(), str2.lower().strip()\n",
    "    cnt = 0\n",
    "    #if len(str1)>0 and len(str2)>0:\n",
    "    #    cnt = len(re.findall(str1,str2))\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_)\n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on=\"product_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print \"Generate count features...\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\n",
    "\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\n",
    "df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']\n",
    "df_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']\n",
    "df_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']\n",
    "df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['ratio_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\n",
    "df_brand = pd.unique(df_all.brand.ravel())\n",
    "d={}\n",
    "i = 1\n",
    "for s in df_brand:\n",
    "    d[s]=i\n",
    "    i+=1\n",
    "df_all['brand_feature'] = df_all['brand'].map(lambda x:d[x])\n",
    "df_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x))\n",
    "\n",
    "# whether has desc or not\n",
    "df_all['isdesc'] = 1\n",
    "df_all.loc[df_all['product_description'].isnull(), 'isdesc'] = 0\n",
    "\n",
    "## get product brand name\n",
    "#brand_names = attribute_data[attribute_data.name == \"MFG Brand Name\"][['product_uid', 'value']].rename(columns={\"value\": \"brand_name\"})\n",
    "#df_all = pd.merge(df_all, brand_names, how='left', on='product_uid')\n",
    "#df_all.brand_name.fillna('Unknown', inplace=True)\n",
    "\n",
    "## indoor/outdoor type\n",
    "#product_type = attribute_data[attribute_data.name == \"Indoor/Outdoor\"][['product_uid', 'value']].rename(columns={\"value\": \"product_type\"})\n",
    "#df_all = pd.merge(df_all, product_type, how='left', on='product_uid')\n",
    "#df_all.product_type.fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "#df_all.to_csv(\"df_all2.csv\")  #no need to keep reprocessing for further grid searches\n",
    "#df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "#df_all.head()\n",
    "\n",
    "print(\"Calculating count feature cost--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['id','search_term','product_title','product_uid', 'relevance','product_description','product_info','attr','brand'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump common word feat\n",
    "np.savetxt(config.path_features + 'common_word_feat.txt', df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jaccard coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_divided(x, y, val=0.0):\n",
    "    if y != 0.0:\n",
    "        val = float(x) / y\n",
    "    return val\n",
    "\n",
    "# Jaccard coefficient between search_term and title & search_term and description\n",
    "def jaccardCoef(A, B):\n",
    "    A, B = set(A), set(B)\n",
    "    intersect = len(A.intersection(B))\n",
    "    union = len(A.union(B))\n",
    "    coef = try_divided(intersect, union)\n",
    "    return coef\n",
    "\n",
    "def diceDist(A, B):\n",
    "    A, B = set(A), set(B)\n",
    "    intersect = len(A.intersection(B))\n",
    "    union  = len(A) + len(B)\n",
    "    d = try_divided(2*intersect, union)\n",
    "    return d\n",
    "\n",
    "def compute_dist(A, B, dist=\"jaccard_coef\"):\n",
    "    if dist == \"jaccard_coef\":\n",
    "        d = jaccardCoef(A, B)\n",
    "    elif dist == \"dice_dist\":\n",
    "        d = diceDist(A, B)\n",
    "    return d\n",
    "\n",
    "def pairwise_jaccard_coef(A, B):\n",
    "    coef = np.zeros((A.shape[0], B.shape[0]), dtype=float)\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(B.shape[0]):\n",
    "            coef[i,j] = jaccardCoef(A[i], B[j])\n",
    "    return coef\n",
    "\n",
    "def pairwise_jaccard_coef(A, B):\n",
    "    d = np.zeros((A.shape[0], B.shape[0]), dtype=float)\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(B.shape[0]):\n",
    "            d[i,j] = diceDist(A[i], B[j])\n",
    "    return d\n",
    "\n",
    "token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "def preprocess_data(line, token_pattern=token_pattern,encode_digit=False):\n",
    "    token_pattern = re.compile(token_pattern, flags=re.UNICODE | re.LOCALE)\n",
    "    # tokenize\n",
    "    tokens = [x.lower() for x in token_pattern.findall(line)]\n",
    "    # stem\n",
    "    tokens_stemmed = stem_tokens(tokens, english_stemmer)\n",
    "    \n",
    "    return tokens_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_basic_distance_feat(df):\n",
    "    ## unigram\n",
    "    print \"generate unigram\"\n",
    "    df[\"term_unigram\"] = list(df.apply(lambda x: preprocess_data(x[\"search_term\"]), axis=1))\n",
    "    df[\"title_unigram\"] = list(df.apply(lambda x: preprocess_data(x[\"product_title\"]), axis=1))\n",
    "    df[\"description_unigram\"] = list(df.apply(lambda x: preprocess_data(x[\"product_description\"]), axis=1))\n",
    "    ## bigram\n",
    "    print \"generate bigram\"\n",
    "    join_str = \"_\"\n",
    "    df[\"term_bigram\"] = list(df.apply(lambda x: ngram.getBigram(x[\"term_unigram\"], join_str), axis=1))\n",
    "    df[\"title_bigram\"] = list(df.apply(lambda x: ngram.getBigram(x[\"title_unigram\"], join_str), axis=1))\n",
    "    df[\"description_bigram\"] = list(df.apply(lambda x: ngram.getBigram(x[\"description_unigram\"], join_str), axis=1))\n",
    "    ## trigram\n",
    "    print \"generate trigram\"\n",
    "    join_str = \"_\"\n",
    "    df[\"term_trigram\"] = list(df.apply(lambda x: ngram.getTrigram(x[\"term_unigram\"], join_str), axis=1))\n",
    "    df[\"title_trigram\"] = list(df.apply(lambda x: ngram.getTrigram(x[\"title_unigram\"], join_str), axis=1))\n",
    "    df[\"description_trigram\"] = list(df.apply(lambda x: ngram.getTrigram(x[\"description_unigram\"], join_str), axis=1))\n",
    " \n",
    "    ## jaccard coef/dice dist of n-gram\n",
    "    print \"generate jaccard coef and dice dist for n-gram\"\n",
    "    dists = [\"jaccard_coef\", \"dice_dist\"]\n",
    "    grams = [\"unigram\", \"bigram\", \"trigram\"]\n",
    "    feat_names = [\"term\", \"title\", \"description\"]\n",
    "    for dist in dists:\n",
    "        for gram in grams:\n",
    "            for i in range(len(feat_names)-1):\n",
    "                for j in range(i+1,len(feat_names)):\n",
    "                    target_name = feat_names[i]\n",
    "                    obs_name = feat_names[j]\n",
    "                    df[\"%s_of_%s_between_%s_%s\"%(dist,gram,target_name,obs_name)] = \\\n",
    "                            list(df.apply(lambda x: compute_dist(x[target_name+\"_\"+gram], x[obs_name+\"_\"+gram], dist), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print \"Generate distince features...\"\n",
    "\n",
    "start_time = time.time()\n",
    "extract_basic_distance_feat(df_all)\n",
    "\n",
    "print(\"Calculating jaccard coef cost--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['id','product_title','product_uid','relevance','search_term','product_description'\n",
    "                      ,'term_unigram', 'title_unigram', 'description_unigram'\n",
    "                      ,'term_bigram', 'title_bigram', 'description_bigram'\n",
    "                      ,'term_trigram', 'title_trigram', 'description_trigram'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_all['term_bigram']\n",
    "df_all.shape\n",
    "\n",
    "# dump df_all file\n",
    "with open('features/jaccard_dice_dist_feat.pkl', 'wb') as f:\n",
    "    cPickle.dump(df_all, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. common word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load common word count features\n",
    "with open('features/common_word_count_feat.pkl', 'rb') as f:\n",
    "    df_all = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info','attr','brand'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Jaccard Coef features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features/jaccard_dice_dist_feat.pkl', 'rb') as f:\n",
    "    jaccard_features = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jaccard_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jaccard_features = jaccard_features.drop(['relevance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jaccard_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.shape, jaccard_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, jaccard_features, how='left', on='id')\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cooccurrence terms column names\n",
    "column_names = [\n",
    "    \"query_unigram_title_unigram\",\n",
    "    \"query_unigram_title_bigram\",\n",
    "    \"query_unigram_description_unigram\",\n",
    "    \"query_unigram_description_bigram\",\n",
    "    \"query_bigram_title_unigram\",\n",
    "    \"query_bigram_title_bigram\",\n",
    "    \"query_bigram_description_unigram\",\n",
    "    \"query_bigram_description_bigram\"\n",
    "]\n",
    "# feature names\n",
    "feat_names = [name + \"_tfidf\" for name in column_names]\n",
    "ngram_range = (1, 3)\n",
    "svd_n_component = 100\n",
    "\n",
    "# Generate co-occurrence tfidf feature\n",
    "extract_cooccurrence_feature(df_train)\n",
    "extract_cooccurrence_feature(df_test)\n",
    "\n",
    "print \"For training and testing...\"\n",
    "\n",
    "for feat_name, column_name in zip(feat_names, column_names):\n",
    "    print \"Generate %s feature\" % feat_name\n",
    "    tfv = getTFV(ngram_range=ngram_range)\n",
    "    X_tfidf_train = tfv.fit_transform(df_train[column_name])\n",
    "    X_tfidf_test = tfv.transform(df_test[column_name])\n",
    "    with open(\"%s/train_%s_feat.pkl\" % (config.path_features, feat_name), \"wb\") as f:\n",
    "        cPickle.dump(X_tfidf_train, f, -1)\n",
    "    with open(\"%s/test_%s_feat.pkl\" % (config.path_features, feat_name), \"wb\") as f:\n",
    "        cPickle.dump(X_tfidf_test, f, -1)\n",
    "\n",
    "    # SVD\n",
    "    svd = TruncatedSVD(n_components=svd_n_component, n_iter=15)\n",
    "    X_svd_train = svd.fit_transform(X_tfidf_train)\n",
    "    X_svd_test = svd.transform(X_tfidf_test)\n",
    "    with open(\"%s/train_%s_individual_svd%d_feat.pkl\" % (config.path_features, feat_name, svd_n_component), \"wb\") as f:\n",
    "        cPickle.dump(X_svd_train, f, -1)\n",
    "    with open(\"%s/test_%s_individual_svd%d_feat.pkl\" % (config.path_features, feat_name, svd_n_component), \"wb\") as f:\n",
    "        cPickle.dump(X_svd_test, f, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cosine Similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load generated cosine features\n",
    "X_cosine_feat_train = np.loadtxt('features/X_cosine_feat_train.txt')\n",
    "X_cosine_feat_test = np.loadtxt('features/X_cosine_feat_test.txt')\n",
    "print type(X_cosine_feat_train)\n",
    "print X_cosine_feat_train.shape, X_cosine_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Word2Vec Similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w2v_feat_train = np.loadtxt('features/X_word2vec_sim_train.txt')\n",
    "X_w2v_feat_test = np.loadtxt('features/X_word2vec_sim_test.txt')\n",
    "print type(X_w2v_feat_train)\n",
    "print X_w2v_feat_train.shape, X_w2v_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extended Query count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_extquery_count_feat_train = np.loadtxt('processed/train_ext_counts_top10.txt')\n",
    "X_extquery_count_feat_test = np.loadtxt('processed/test_ext_counts_top10.txt')\n",
    "print type(X_extquery_count_feat_train)\n",
    "print X_extquery_count_feat_train.shape, X_extquery_count_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def fmean_squarded_error(ground_truth, prediction):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, prediction) ** 0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "RMSE = make_scorer(fmean_squarded_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id', 'relevance','product_uid'], axis=1)\n",
    "X_test = df_test.drop(['id', 'relevance','product_uid'], axis=1)\n",
    "#X_train = df_train.drop(['id', 'relevance','product_uid', 'product_title', 'search_term', 'term_unigram', 'title_unigram', 'description_unigram'], axis=1)\n",
    "#X_test = df_test.drop(['id', 'relevance','product_uid', 'product_title', 'search_term', 'term_unigram', 'title_unigram', 'description_unigram'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_count = np.loadtxt('features/train_counts.txt')\n",
    "X_test_count = np.loadtxt('features/test_counts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape, X_train_count.shape, X_cosine_feat_train.shape, X_w2v_feat_train.shape, X_extquery_count_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_test.shape, X_test_count.shape, X_cosine_feat_test.shape, X_w2v_feat_test.shape, X_extquery_count_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge features\n",
    "X_train = np.array(X_train)\n",
    "X_train = np.hstack((X_train, X_train_count, X_cosine_feat_train, X_w2v_feat_train, X_extquery_count_feat_train))\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.hstack((X_test, X_test_count, X_cosine_feat_test, X_w2v_feat_test, X_extquery_count_feat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model Random Froest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "clf = pipeline.Pipeline([('rfr', rfr)])\n",
    "param_grid_old = {'rfr__n_estimators' : list(range(320, 400 ,1)), 'rfr__max_depth': list(range(8,10,1))}\n",
    "param_grid = {'rfr__n_estimators' : [350],#list(range(109,110,1)), \n",
    "              'rfr__max_depth': [8], #list(range(7,8,1))\n",
    "            }\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid,\n",
    "                                 n_jobs = 2, cv = 10, verbose = 1, scoring=RMSE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission/rf_fe_addCosineW2cExt_20160210_tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 200, 'max_depth': 7, 'min_samples_split': 1,\n",
    "          'learning_rate': 0.2, 'loss': 'ls'}\n",
    "clf = GradientBoostingRegressor(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_GBM = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def output(x):\n",
    "    if x < 1:\n",
    "        return 1\n",
    "    elif x > 3:\n",
    "        return 3\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = [output(x) for x in y_pred_GBM]\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": result}).to_csv('submission/gbm_fe_20160129_tune.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)  \n",
    "\n",
    "params ={\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'min_child_weight': 4.0,\n",
    "    'n_estimators': 380.0,\n",
    "    'subsample': 0.55,\n",
    "    'eta': 0.03,\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 10,\n",
    "    'max_depth': 6,\n",
    "    'gamma': 0.75}\n",
    "\n",
    "cv_nround=1000\n",
    "cv_nfold=10\n",
    "#bst_cv = xgb.cv(params, dtrain, nfold=cv_nfold, num_boost_round=cv_nround\n",
    "#                , early_stopping_rounds=10, show_progress=True)\n",
    "clf = xgb.train(params, dtrain, 599)\n",
    "y_pred = clf.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = [output(x) for x in y_pred]\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": result}).to_csv('submission/xgb_fe_20160210_tune_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using SVM regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn import grid_search\n",
    "\n",
    "svr = SVR()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "\n",
    "clf = grid_search.GridSearchCV(estimator = svr, param_grid = parameters,\n",
    "                                 n_jobs = -1, cv = 3, verbose = 10, scoring=RMSE)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = [output(x) for x in y_pred]\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": result}).to_csv('submission/svm_fe_20160129_tune.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
