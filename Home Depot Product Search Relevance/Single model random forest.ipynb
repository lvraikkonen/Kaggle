{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ngram\n",
    "from nlp_utils import stopwords, english_stemmer, stem_tokens, getTFV\n",
    "import cPickle\n",
    "import config\n",
    "\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import decomposition, pipeline, metrics, grid_search\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from nltk.stem.porter import *\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "from utility import correct_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('input/train.csv', encoding='ISO-8859-1')\n",
    "df_test = pd.read_csv('input/test.csv', encoding='ISO-8859-1')\n",
    "df_pro_desc = pd.read_csv('input/product_descriptions.csv', encoding='ISO-8859-1')\n",
    "df_attr = pd.read_csv('input/attributes.csv')\n",
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "y_train = df_train['relevance'].values\n",
    "id_test = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74067 entries, 0 to 74066\n",
      "Data columns (total 5 columns):\n",
      "id               74067 non-null int64\n",
      "product_uid      74067 non-null int64\n",
      "product_title    74067 non-null object\n",
      "search_term      74067 non-null object\n",
      "relevance        74067 non-null float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 3.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 166693 entries, 0 to 166692\n",
      "Data columns (total 4 columns):\n",
      "id               166693 non-null int64\n",
      "product_uid      166693 non-null int64\n",
      "product_title    166693 non-null object\n",
      "search_term      166693 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 6.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. common word count feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_common_word_feat_train = np.loadtxt(config.path_features + 'common_word_feat_train.txt')\n",
    "X_common_word_feat_test = np.loadtxt(config.path_features + 'common_word_feat_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74067, 17), (166693, 17))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_common_word_feat_train.shape, X_common_word_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_common_word_feat_test[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. jaccard coef feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './features/jaccard_dice_dist_feat_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c4811fe77c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_jaccard_feat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'jaccard_dice_dist_feat_train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_jaccard_feat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'jaccard_dice_dist_feat_test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './features/jaccard_dice_dist_feat_train.txt'"
     ]
    }
   ],
   "source": [
    "X_jaccard_feat_train = np.loadtxt(config.path_features + 'jaccard_dice_dist_feat_train.txt')\n",
    "X_jaccard_feat_test = np.loadtxt(config.path_features + 'jaccard_dice_dist_feat_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_jaccard_feat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9758a386af45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_jaccard_feat_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_jaccard_feat_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_jaccard_feat_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_jaccard_feat_train.shape, X_jaccard_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. similiarity feature (word2vec, cosine sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74067, 6) (166693, 6)\n"
     ]
    }
   ],
   "source": [
    "X_sim_feat_train = np.loadtxt(config.path_features + 'X_similiarity_additional_train.txt')\n",
    "X_sim_feat_test = np.loadtxt(config.path_features + 'X_similiarity_additional_test.txt')\n",
    "print X_sim_feat_train.shape, X_sim_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. counts feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74067, 9) (166693, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train_count = np.loadtxt(config.path_features + 'train_counts.txt')\n",
    "X_test_count = np.loadtxt(config.path_features + 'test_counts.txt')\n",
    "print X_train_count.shape, X_test_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. extended query count features (top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(74067, 6) (166693, 6)\n"
     ]
    }
   ],
   "source": [
    "X_extquery_count_feat_train = np.loadtxt(config.path_features + 'train_ext_counts_top10.txt')\n",
    "X_extquery_count_feat_test = np.loadtxt(config.path_features + 'test_ext_counts_top10.txt')\n",
    "print type(X_extquery_count_feat_train)\n",
    "print X_extquery_count_feat_train.shape, X_extquery_count_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. extended query count features (top 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_extquery_count_feat_train = np.loadtxt(config.path_features + 'train_ext_counts_top15.txt')\n",
    "X_extquery_count_feat_test = np.loadtxt(config.path_features + 'test_ext_counts_top15.txt')\n",
    "print type(X_extquery_count_feat_train)\n",
    "print X_extquery_count_feat_train.shape, X_extquery_count_feat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. char similiarity feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74067, 27) (166693, 27)\n"
     ]
    }
   ],
   "source": [
    "X_char_sim_train = np.loadtxt(config.path_features + 'ssfeas4train.txt')\n",
    "X_char_sim_test = np.loadtxt(config.path_features + 'ssfeas4test.txt')\n",
    "print X_char_sim_train.shape, X_char_sim_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge all features\n",
    "X_train = np.hstack((X_common_word_feat_train\n",
    "                     #, X_jaccard_feat_train \n",
    "                     , X_sim_feat_train\n",
    "                     , X_train_count\n",
    "                     , X_extquery_count_feat_train, X_char_sim_train))\n",
    "X_test = np.hstack((X_common_word_feat_test\n",
    "                     #, X_jaccard_feat_test\n",
    "                     , X_sim_feat_test\n",
    "                     , X_test_count\n",
    "                     , X_extquery_count_feat_test, X_char_sim_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74067, 65), (166693, 65))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def fmean_squarded_error(ground_truth, prediction):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, prediction) ** 0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "RMSE = make_scorer(fmean_squarded_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model Random Froest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best parameters found by grid search:\n",
      "{'rfr__n_estimators': 260, 'rfr__max_depth': 8}\n",
      "Best CV score:\n",
      "-0.468753424833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed: 18.4min finished\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "clf = pipeline.Pipeline([('rfr', rfr)])\n",
    "param_grid_old = {'rfr__n_estimators' : list(range(320, 400 ,1)), 'rfr__max_depth': list(range(8,10,1))}\n",
    "param_grid = {'rfr__n_estimators' : [260],#list(range(109,110,1)), \n",
    "              'rfr__max_depth': [8], #list(range(7,8,1))\n",
    "            }\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid,\n",
    "                                 n_jobs = 2, cv = 5, verbose = 1, scoring=RMSE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "clf = pipeline.Pipeline([('rfr', rfr)])\n",
    "param_grid_old = {'rfr__n_estimators' : list(range(320, 400 ,1)), 'rfr__max_depth': list(range(8,10,1))}\n",
    "param_grid = {'rfr__n_estimators' : [350],#list(range(109,110,1)), \n",
    "              'rfr__max_depth': [8], #list(range(7,8,1))\n",
    "            }\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid,\n",
    "                                 n_jobs = 2, cv = 10, verbose = 1, scoring=RMSE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission/rf_fe_tuned_20160222.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)  \n",
    "\n",
    "params ={\n",
    "    'colsample_bytree': 0.7,\n",
    "    #'silent': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'min_child_weight': 4.0,\n",
    "    'n_estimators': 380.0,\n",
    "    'subsample': 0.55,\n",
    "    'eta': 0.05,\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 2016,\n",
    "    'max_depth': 7,\n",
    "    'gamma': 0.75}\n",
    "\n",
    "cv_nround=1000\n",
    "cv_nfold=10\n",
    "#bst_cv = xgb.cv(params, dtrain, nfold=cv_nfold, num_boost_round=cv_nround\n",
    "#                , early_stopping_rounds=10, show_progress=True)\n",
    "clf = xgb.train(params, dtrain, 646)\n",
    "y_pred = clf.predict(dtest)\n",
    "def output(x):\n",
    "    if x < 1:\n",
    "        return 1\n",
    "    elif x > 3:\n",
    "        return 3\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "result = [output(x) for x in y_pred]\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": result}).to_csv('submission/xgb_fe_20160222_tune.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
